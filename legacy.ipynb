{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tự định nghĩa để chia dữ liệu thành train/val/test\n",
    "def custom_train_test_split(X, y, train_size=0.5, val_size=0.4, test_size=0.1, random_state=42):\n",
    "    assert abs(train_size + val_size + test_size - 1.0) < 1e-6, \"Tổng tỷ lệ train_size, val_size, test_size phải bằng 1\"\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    n_samples = X.shape[0]\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_end = int(train_size * n_samples)\n",
    "    val_end = train_end + int(val_size * n_samples)\n",
    "    \n",
    "    train_indices = indices[:train_end]\n",
    "    val_indices = indices[train_end:val_end]\n",
    "    test_indices = indices[val_end:]\n",
    "    \n",
    "    X_train = X[train_indices]\n",
    "    X_val = X[val_indices]\n",
    "    X_test = X[test_indices]\n",
    "    \n",
    "    y_train = y[train_indices]\n",
    "    y_val = y[val_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa class Model\n",
    "class Model():\n",
    "    def __init__(self, data, regression_type='standard', lr=0.0001, epochs=100, batch_size=32, optimizer='batch', \n",
    "                 lambda_reg=1.0, use_log=False, scale_type='normalize'):\n",
    "        # Chia dữ liệu thành train/val/test\n",
    "        self.X_train, self.X_val, self.X_test, self.y_train, self.y_val, self.y_test = custom_train_test_split(\n",
    "            data[:, :-1], data[:, -1], train_size=0.5, val_size=0.4, test_size=0.1, random_state=42)\n",
    "        \n",
    "        self.y_train_original = self.y_train.copy()\n",
    "        self.y_val_original = self.y_val.copy()\n",
    "        self.y_test_original = self.y_test.copy()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.regression_type = regression_type\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.use_log = use_log\n",
    "        self.scale_type = scale_type\n",
    "        \n",
    "        # Scale dữ liệu\n",
    "        if self.scale_type == 'normalize':\n",
    "            self.X_train, self.X_mean, self.X_std = normalize(self.X_train)\n",
    "            self.X_val = (self.X_val - self.X_mean) / self.X_std\n",
    "            self.X_test = (self.X_test - self.X_mean) / self.X_std\n",
    "        elif self.scale_type == 'minmax':\n",
    "            self.X_train, self.X_min, self.X_max = minmax_scale(self.X_train)\n",
    "            self.X_val = (self.X_val - self.X_min) / (self.X_max - self.X_min)\n",
    "            self.X_test = (self.X_test - self.X_min) / (self.X_max - self.X_min)\n",
    "        \n",
    "        # Scale y nếu cần\n",
    "        if self.use_log:\n",
    "            self.y_train = np.log(self.y_train + 1)\n",
    "            self.y_val = np.log(self.y_val + 1)\n",
    "            self.y_test = np.log(self.y_test + 1)\n",
    "        elif self.scale_type == 'minmax':\n",
    "            self.y_train, self.y_min, self.y_max = minmax_scale(self.y_train.reshape(-1, 1))\n",
    "            self.y_val = (self.y_val - self.y_min) / (self.y_max - self.y_min)\n",
    "            self.y_test = (self.y_test - self.y_min) / (self.y_max - self.y_min)\n",
    "        \n",
    "        # Thêm cột bias\n",
    "        self.X_train = np.hstack((np.ones((self.X_train.shape[0], 1)), self.X_train))\n",
    "        self.X_val = np.hstack((np.ones((self.X_val.shape[0], 1)), self.X_val))\n",
    "        self.X_test = np.hstack((np.ones((self.X_test.shape[0], 1)), self.X_test))\n",
    "        \n",
    "        self._prepare_features()\n",
    "        \n",
    "        print(f\"Max X_train: {np.max(self.X_train)}, Min X_train: {np.min(self.X_train)}\")\n",
    "        if np.any(np.isnan(self.X_train)) or np.any(np.isinf(self.X_train)):\n",
    "            print(\"Warning: NaN or Inf detected in X_train after _prepare_features\")\n",
    "        \n",
    "        self.weight = np.random.randn(self.X_train.shape[1], 1) * 0.01\n",
    "        \n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.epsilon = 1e-8\n",
    "        self.m = np.zeros_like(self.weight)\n",
    "        self.v = np.zeros_like(self.weight)\n",
    "        self.t = 0\n",
    "    \n",
    "    def _prepare_features(self):\n",
    "        if self.regression_type == 'standard':\n",
    "            pass\n",
    "        elif self.regression_type == 'polynomial':\n",
    "            self.X_train = np.vstack([self.X_train[:, 0], self.X_train[:, 1]**2, self.X_train[:, 2], \n",
    "                                    self.X_train[:, 3]**2, self.X_train[:, 4],\n",
    "                                    self.X_train[:, 5], self.X_train[:, 6]**2,\n",
    "                                    self.X_train[:, 7], self.X_train[:, 8]**2,\n",
    "                                    self.X_train[:, 9]]).T\n",
    "            self.X_val = np.vstack([self.X_val[:, 0], self.X_val[:, 1]**2, self.X_val[:, 2], \n",
    "                                   self.X_val[:, 3]**2, self.X_val[:, 4],\n",
    "                                   self.X_val[:, 5], self.X_val[:, 6]**2,\n",
    "                                   self.X_val[:, 7], self.X_val[:, 8]**2,\n",
    "                                   self.X_val[:, 9]]).T\n",
    "            self.X_test = np.vstack([self.X_test[:, 0], self.X_test[:, 1]**2, self.X_test[:, 2], \n",
    "                                   self.X_test[:, 3]**2, self.X_test[:, 4],\n",
    "                                   self.X_test[:, 5], self.X_test[:, 6]**2,\n",
    "                                   self.X_test[:, 7], self.X_test[:, 8]**2,\n",
    "                                   self.X_test[:, 9]]).T\n",
    "        elif self.regression_type == 'mixed':\n",
    "            self.X_train = np.vstack([self.X_train[:, 0], self.X_train[:, 1] + self.X_train[:, 2], \n",
    "                                    self.X_train[:, 3]**2, self.X_train[:, 4],\n",
    "                                    self.X_train[:, 5], self.X_train[:, 6],\n",
    "                                    self.X_train[:, 7]**2, self.X_train[:, 8],\n",
    "                                    self.X_train[:, 9]]).T\n",
    "            self.X_val = np.vstack([self.X_val[:, 0], self.X_val[:, 1] + self.X_val[:, 2], \n",
    "                                   self.X_val[:, 3]**2, self.X_val[:, 4],\n",
    "                                   self.X_val[:, 5], self.X_val[:, 6],\n",
    "                                   self.X_val[:, 7]**2, self.X_val[:, 8],\n",
    "                                   self.X_val[:, 9]]).T\n",
    "            self.X_test = np.vstack([self.X_test[:, 0], self.X_test[:, 1] + self.X_test[:, 2], \n",
    "                                   self.X_test[:, 3]**2, self.X_test[:, 4],\n",
    "                                   self.X_test[:, 5], self.X_test[:, 6],\n",
    "                                   self.X_test[:, 7]**2, self.X_test[:, 8],\n",
    "                                   self.X_test[:, 9]]).T\n",
    "        elif self.regression_type == 'interaction':\n",
    "            self.X_train = np.vstack([self.X_train[:, 0], self.X_train[:, 1] * self.X_train[:, 2], \n",
    "                                    self.X_train[:, 3]**2, self.X_train[:, 4],\n",
    "                                    self.X_train[:, 5] * self.X_train[:, 6],\n",
    "                                    self.X_train[:, 7], self.X_train[:, 8]**2,\n",
    "                                    self.X_train[:, 9]]).T\n",
    "            self.X_val = np.vstack([self.X_val[:, 0], self.X_val[:, 1] * self.X_val[:, 2], \n",
    "                                   self.X_val[:, 3]**2, self.X_val[:, 4],\n",
    "                                   self.X_val[:, 5] * self.X_val[:, 6],\n",
    "                                   self.X_val[:, 7], self.X_val[:, 8]**2,\n",
    "                                   self.X_val[:, 9]]).T\n",
    "            self.X_test = np.vstack([self.X_test[:, 0], self.X_test[:, 1] * self.X_test[:, 2], \n",
    "                                   self.X_test[:, 3]**2, self.X_test[:, 4],\n",
    "                                   self.X_test[:, 5] * self.X_test[:, 6],\n",
    "                                   self.X_test[:, 7], self.X_test[:, 8]**2,\n",
    "                                   self.X_test[:, 9]]).T\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.dot(X, self.weight)\n",
    "        if self.use_log:\n",
    "            y_pred = np.clip(y_pred, -100, 100)\n",
    "            y_pred = np.exp(y_pred) - 1\n",
    "        elif self.scale_type == 'minmax':\n",
    "            y_pred = y_pred * (self.y_max - self.y_min) + self.y_min\n",
    "        return y_pred\n",
    "    \n",
    "    def gradient(self, X, y, y_hat):\n",
    "        grad = 2 * np.dot(X.T, (y_hat - y.reshape(-1, 1))) / len(y)\n",
    "        if np.any(np.isnan(grad)) or np.any(np.isinf(grad)):\n",
    "            print(\"Warning: NaN or Inf detected in gradient\")\n",
    "        return grad\n",
    "    \n",
    "    def ridge_gradient(self, X, y, y_hat):\n",
    "        grad = self.gradient(X, y, y_hat) + 2 * self.lambda_reg * self.weight\n",
    "        return grad\n",
    "    \n",
    "    def batch_gradient_descent(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            y_hat = self.predict(self.X_train)\n",
    "            grad = self.gradient(self.X_train, self.y_train, y_hat)\n",
    "            self.weight -= self.lr * grad\n",
    "            if epoch % 10 == 0:\n",
    "                loss = mse(self.y_train.reshape(-1, 1), y_hat)\n",
    "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "    \n",
    "    def stochastic_gradient_descent(self):\n",
    "        n_samples = len(self.X_train)\n",
    "        indices = np.arange(n_samples)\n",
    "        for epoch in range(self.epochs):\n",
    "            np.random.shuffle(indices)\n",
    "            total_loss = 0\n",
    "            for idx in indices:\n",
    "                X_i = self.X_train[idx:idx+1]\n",
    "                y_i = self.y_train[idx:idx+1]\n",
    "                y_hat = self.predict(X_i)\n",
    "                grad = self.gradient(X_i, y_i, y_hat)\n",
    "                self.weight -= self.lr * grad\n",
    "                total_loss += mse(y_i.reshape(-1, 1), y_hat)\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Average Loss: {total_loss/n_samples:.4f}')\n",
    "    \n",
    "    def adam_optimizer(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            self.t += 1\n",
    "            y_hat = self.predict(self.X_train)\n",
    "            grad = self.gradient(self.X_train, self.y_train, y_hat)\n",
    "            self.m = self.beta1 * self.m + (1 - self.beta1) * grad\n",
    "            self.v = self.beta2 * self.v + (1 - self.beta2) * (grad ** 2)\n",
    "            m_hat = self.m / (1 - self.beta1 ** self.t)\n",
    "            v_hat = self.v / (1 - self.beta2 ** self.t)\n",
    "            self.weight -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "            if epoch % 10 == 0:\n",
    "                loss = mse(self.y_train.reshape(-1, 1), y_hat)\n",
    "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "                if np.isnan(loss) or np.isinf(loss):\n",
    "                    print(\"Training stopped due to NaN/Inf loss\")\n",
    "                    break\n",
    "    \n",
    "    def pseudo_inverse(self):\n",
    "        X = self.X_train\n",
    "        y = self.y_train.reshape(-1, 1)\n",
    "        self.weight = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "        loss = mse(self.y_train.reshape(-1, 1), self.predict(X))\n",
    "        print(f'Pseudo-inverse Loss: {loss:.4f}')\n",
    "    \n",
    "    def ridge_analytical(self):\n",
    "        X = self.X_train\n",
    "        y = self.y_train.reshape(-1, 1)\n",
    "        n_features = X.shape[1]\n",
    "        I = np.eye(n_features)\n",
    "        self.weight = np.linalg.inv(X.T @ X + self.lambda_reg * I) @ X.T @ y\n",
    "        loss = mse(self.y_train.reshape(-1, 1), self.predict(X)) + self.lambda_reg * np.sum(self.weight ** 2)\n",
    "        print(f'Ridge Analytical Loss: {loss:.4f}')\n",
    "    \n",
    "    def ridge_gradient_descent(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            y_hat = self.predict(self.X_train)\n",
    "            grad = self.ridge_gradient(self.X_train, self.y_train, y_hat)\n",
    "            self.weight -= self.lr * grad\n",
    "            if epoch % 10 == 0:\n",
    "                loss = mse(self.y_train.reshape(-1, 1), y_hat) + self.lambda_reg * np.sum(self.weight ** 2)\n",
    "                print(f'Epoch {epoch}, Ridge Loss: {loss:.4f}')\n",
    "                if np.isnan(loss) or np.isinf(loss):\n",
    "                    print(\"Training stopped due to NaN/Inf loss\")\n",
    "                    break\n",
    "    \n",
    "    def least_squares(self):\n",
    "        X = self.X_train\n",
    "        y = self.y_train.reshape(-1, 1)\n",
    "        self.weight, residuals, rank, s = np.linalg.lstsq(X, y, rcond=None)\n",
    "        loss = mse(self.y_train.reshape(-1, 1), self.predict(X)) if residuals.size == 0 else residuals[0]\n",
    "        print(f'Least Squares Loss: {loss:.4f}')\n",
    "    \n",
    "    def fit(self):\n",
    "        if self.optimizer == 'batch':\n",
    "            self.batch_gradient_descent()\n",
    "        elif self.optimizer == 'sgd':\n",
    "            self.stochastic_gradient_descent()\n",
    "        elif self.optimizer == 'adam':\n",
    "            self.adam_optimizer()\n",
    "        elif self.optimizer == 'pseudo':\n",
    "            self.pseudo_inverse()\n",
    "        elif self.optimizer == 'ridge_analytical':\n",
    "            self.ridge_analytical()\n",
    "        elif self.optimizer == 'ridge_gd':\n",
    "            self.ridge_gradient_descent()\n",
    "        elif self.optimizer == 'least_squares':\n",
    "            self.least_squares()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tính MSE\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Hàm tính MAE\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đọc dữ liệu từ file CSV\n",
    "def load_data_from_csv(file_path):\n",
    "    required_columns = ['Year', 'Engine', 'Length', 'Width', 'Fuel Tank Capacity', \n",
    "                        'Max Power BHP', 'Max Power RPM', 'Max Torque Nm', 'Max Torque RPM', 'Price']\n",
    "    data = []\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            if not all(col in reader.fieldnames for col in required_columns):\n",
    "                raise ValueError(\"File CSV thiếu một hoặc nhiều cột cần thiết!\")\n",
    "            \n",
    "            for row in reader:\n",
    "                row_data = []\n",
    "                for col in required_columns:\n",
    "                    value = row[col].strip()\n",
    "                    if value:\n",
    "                        row_data.append(float(value))\n",
    "                    else:\n",
    "                        row_data.append(0.0)\n",
    "                data.append(row_data)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Không tìm thấy file: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file CSV: {e}\")\n",
    "        raise\n",
    "    \n",
    "    data = np.array(data)\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "    return X, y\n",
    "\n",
    "# Chuẩn hóa dữ liệu (StandardScaler: mean=0, std=1)\n",
    "def normalize(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    std[std == 0] = 1.0\n",
    "    X_normalized = (X - mean) / std\n",
    "    return X_normalized, mean, std\n",
    "\n",
    "# Scale dữ liệu (MinMaxScaler: [0, 1])\n",
    "def minmax_scale(X, min_range=0, max_range=1):\n",
    "    X_min = np.min(X, axis=0)\n",
    "    X_max = np.max(X, axis=0)\n",
    "    X_range = X_max - X_min\n",
    "    mask = X_range == 0\n",
    "    X_range[mask] = 1.0\n",
    "    X_scaled = (X - X_min) / X_range * (max_range - min_range) + min_range\n",
    "    X_scaled[:, mask] = X[:, mask]\n",
    "    return X_scaled, X_min, X_max# Hàm đọc dữ liệu từ file CSV\n",
    "def load_data_from_csv(file_path):\n",
    "    required_columns = ['Year', 'Engine', 'Length', 'Width', 'Fuel Tank Capacity', \n",
    "                        'Max Power BHP', 'Max Power RPM', 'Max Torque Nm', 'Max Torque RPM', 'Price']\n",
    "    data = []\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            if not all(col in reader.fieldnames for col in required_columns):\n",
    "                raise ValueError(\"File CSV thiếu một hoặc nhiều cột cần thiết!\")\n",
    "            \n",
    "            for row in reader:\n",
    "                row_data = []\n",
    "                for col in required_columns:\n",
    "                    value = row[col].strip()\n",
    "                    if value:\n",
    "                        row_data.append(float(value))\n",
    "                    else:\n",
    "                        row_data.append(0.0)\n",
    "                data.append(row_data)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Không tìm thấy file: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file CSV: {e}\")\n",
    "        raise\n",
    "    \n",
    "    data = np.array(data)\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "    return X, y\n",
    "\n",
    "# Chuẩn hóa dữ liệu (StandardScaler: mean=0, std=1)\n",
    "def normalize(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    std[std == 0] = 1.0\n",
    "    X_normalized = (X - mean) / std\n",
    "    return X_normalized, mean, std\n",
    "\n",
    "# Scale dữ liệu (MinMaxScaler: [0, 1])\n",
    "def minmax_scale(X, min_range=0, max_range=1):\n",
    "    X_min = np.min(X, axis=0)\n",
    "    X_max = np.max(X, axis=0)\n",
    "    X_range = X_max - X_min\n",
    "    mask = X_range == 0\n",
    "    X_range[mask] = 1.0\n",
    "    X_scaled = (X - X_min) / X_range * (max_range - min_range) + min_range\n",
    "    X_scaled[:, mask] = X[:, mask]\n",
    "    return X_scaled, X_min, X_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ file CSV\n",
    "file_path = './data/train_mean.csv'\n",
    "X, y = load_data_from_csv(file_path)\n",
    "data = np.hstack((X, y.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max X_train: 1.0, Min X_train: 0.0\n",
      "Max X_train: 98.16009310257178, Min X_train: -2.534156404924392\n",
      "Max X_train: 10.449421621520598, Min X_train: -6.1984996543181525\n",
      "Max X_train: 1.0, Min X_train: 0.0\n",
      "\n",
      "Training: Standard Linear Regression with Least Squares\n",
      "Least Squares Loss: 2.5312\n",
      "Number of weights: 10\n",
      "Weights: [-0.24574932  0.2238761  -0.13380438 -0.04374224 -0.0411989   0.09068511\n",
      "  0.80487626 -0.05653534  0.03497721  0.04400134]\n",
      "\n",
      "Predictions vs True Values (Validation Set):\n",
      "Index | Predicted Price | True Price\n",
      "    0 |       969886.88 |       550000.00\n",
      "    1 |       649743.61 |       240000.00\n",
      "    2 |       750002.65 |       295000.00\n",
      "    3 |      -512444.94 |       380000.00\n",
      "    4 |      2123165.84 |      1299000.00\n",
      "    5 |       516907.84 |       550000.00\n",
      "    6 |       406355.86 |       591000.00\n",
      "    7 |       771846.25 |       145000.00\n",
      "    8 |      1957188.97 |      1375000.00\n",
      "    9 |      3674602.63 |      6000000.00\n",
      "\n",
      "Validation MSE: 2305515634249.5459\n",
      "Validation MAE: 795281.6795\n",
      "\n",
      "Predictions vs True Values (Test Set):\n",
      "Index | Predicted Price | True Price\n",
      "    0 |      2677938.05 |      1639999.00\n",
      "    1 |      5038274.93 |      5500000.00\n",
      "    2 |      2545813.72 |      1475000.00\n",
      "    3 |       622031.13 |       795000.00\n",
      "    4 |      1949056.95 |      1260000.00\n",
      "    5 |       273974.68 |       960000.00\n",
      "    6 |       594608.02 |       725000.00\n",
      "    7 |       117085.91 |       425000.00\n",
      "    8 |       543769.71 |       250000.00\n",
      "    9 |      -284674.30 |       265000.00\n",
      "\n",
      "Test MSE: 879472290345.3737\n",
      "Test MAE: 674262.4388\n",
      "\n",
      "Training: Polynomial Regression with Ridge Gradient Descent\n",
      "Epoch 0, Ridge Loss: 192.1021\n",
      "Epoch 10, Ridge Loss: 187.1362\n",
      "Epoch 20, Ridge Loss: 183.6440\n",
      "Epoch 30, Ridge Loss: 188.2209\n",
      "Epoch 40, Ridge Loss: 194.4409\n",
      "Number of weights: 10\n",
      "Weights: [ 0.13312284  0.11117166  0.00741011  0.1075707   0.00048492  0.00853152\n",
      "  0.07884216 -0.00838728  0.0210505   0.01180091]\n",
      "\n",
      "Predictions vs True Values (Validation Set):\n",
      "Index | Predicted Price | True Price\n",
      "    0 |            0.17 |       550000.00\n",
      "    1 |            0.98 |       240000.00\n",
      "    2 |            0.40 |       295000.00\n",
      "    3 |            0.35 |       380000.00\n",
      "    4 |            0.21 |      1299000.00\n",
      "    5 |            0.39 |       550000.00\n",
      "    6 |            0.26 |       591000.00\n",
      "    7 |            1.73 |       145000.00\n",
      "    8 |            0.51 |      1375000.00\n",
      "    9 |            0.77 |      6000000.00\n",
      "\n",
      "Validation MSE: 9296541458692.1270\n",
      "Validation MAE: 1757022.6294\n",
      "\n",
      "Predictions vs True Values (Test Set):\n",
      "Index | Predicted Price | True Price\n",
      "    0 |            0.26 |      1639999.00\n",
      "    1 |            1.09 |      5500000.00\n",
      "    2 |            0.48 |      1475000.00\n",
      "    3 |            0.18 |       795000.00\n",
      "    4 |            0.19 |      1260000.00\n",
      "    5 |            0.48 |       960000.00\n",
      "    6 |            0.17 |       725000.00\n",
      "    7 |            0.29 |       425000.00\n",
      "    8 |            0.55 |       250000.00\n",
      "    9 |            0.98 |       265000.00\n",
      "\n",
      "Test MSE: 5398623251496.7285\n",
      "Test MAE: 1450571.6352\n",
      "\n",
      "Training: Mixed Terms Regression with Adam\n",
      "Epoch 0, Loss: 191.1517\n",
      "Epoch 10, Loss: 191.0594\n",
      "Epoch 20, Loss: 190.9662\n",
      "Epoch 30, Loss: 190.8721\n",
      "Epoch 40, Loss: 190.7771\n",
      "Number of weights: 9\n",
      "Weights: [ 0.00632902 -0.00201557  0.01694939 -0.01024706 -0.00060664  0.00875416\n",
      "  0.02065437  0.00332896 -0.01053552]\n",
      "\n",
      "Predictions vs True Values (Validation Set):\n",
      "Index | Predicted Price | True Price\n",
      "    0 |            0.01 |       550000.00\n",
      "    1 |            0.04 |       240000.00\n",
      "    2 |            0.01 |       295000.00\n",
      "    3 |            0.04 |       380000.00\n",
      "    4 |            0.03 |      1299000.00\n",
      "    5 |            0.04 |       550000.00\n",
      "    6 |            0.02 |       591000.00\n",
      "    7 |            0.09 |       145000.00\n",
      "    8 |            0.06 |      1375000.00\n",
      "    9 |            0.06 |      6000000.00\n",
      "\n",
      "Validation MSE: 9296584857220.3262\n",
      "Validation MAE: 1757033.3452\n",
      "\n",
      "Predictions vs True Values (Test Set):\n",
      "Index | Predicted Price | True Price\n",
      "    0 |            0.03 |      1639999.00\n",
      "    1 |            0.14 |      5500000.00\n",
      "    2 |            0.04 |      1475000.00\n",
      "    3 |            0.02 |       795000.00\n",
      "    4 |            0.03 |      1260000.00\n",
      "    5 |            0.01 |       960000.00\n",
      "    6 |            0.03 |       725000.00\n",
      "    7 |            0.01 |       425000.00\n",
      "    8 |            0.01 |       250000.00\n",
      "    9 |            0.11 |       265000.00\n",
      "\n",
      "Test MSE: 5398625497322.8916\n",
      "Test MAE: 1450572.1989\n",
      "\n",
      "Training: Interaction Terms Regression with Least Squares\n",
      "Least Squares Loss: 3.1214\n",
      "Number of weights: 8\n",
      "Weights: [-0.05807065  0.46133157 -0.05199142  0.01339151  0.5141892   0.10275679\n",
      "  0.0047429  -0.06945129]\n",
      "\n",
      "Predictions vs True Values (Validation Set):\n",
      "Index | Predicted Price | True Price\n",
      "    0 |       983997.40 |       550000.00\n",
      "    1 |       710990.24 |       240000.00\n",
      "    2 |      1221801.51 |       295000.00\n",
      "    3 |         9746.85 |       380000.00\n",
      "    4 |      1581626.33 |      1299000.00\n",
      "    5 |       526001.64 |       550000.00\n",
      "    6 |       529106.09 |       591000.00\n",
      "    7 |        31642.83 |       145000.00\n",
      "    8 |      3820462.11 |      1375000.00\n",
      "    9 |      2522644.57 |      6000000.00\n",
      "\n",
      "Validation MSE: 2351448770491.1611\n",
      "Validation MAE: 809368.8019\n",
      "\n",
      "Predictions vs True Values (Test Set):\n",
      "Index | Predicted Price | True Price\n",
      "    0 |      2883657.50 |      1639999.00\n",
      "    1 |      4786202.54 |      5500000.00\n",
      "    2 |      2873443.38 |      1475000.00\n",
      "    3 |       726078.72 |       795000.00\n",
      "    4 |      1677578.77 |      1260000.00\n",
      "    5 |      2059576.53 |       960000.00\n",
      "    6 |       289103.01 |       725000.00\n",
      "    7 |       219099.32 |       425000.00\n",
      "    8 |      1145062.06 |       250000.00\n",
      "    9 |      -209807.74 |       265000.00\n",
      "\n",
      "Test MSE: 1077699337230.5087\n",
      "Test MAE: 666103.3772\n"
     ]
    }
   ],
   "source": [
    "# Train và predict trên tập test\n",
    "models = [\n",
    "    (\"Standard Linear Regression with Least Squares\", Model(data, regression_type='standard', optimizer='least_squares', use_log=False, scale_type='minmax')),\n",
    "    (\"Polynomial Regression with Ridge Gradient Descent\", Model(data, regression_type='polynomial', optimizer='ridge_gd', epochs=50, lambda_reg=1.0, use_log=True, scale_type='normalize')),\n",
    "    (\"Mixed Terms Regression with Adam\", Model(data, regression_type='mixed', optimizer='adam', epochs=50, use_log=True, scale_type='normalize')),\n",
    "    (\"Interaction Terms Regression with Least Squares\", Model(data, regression_type='interaction', optimizer='least_squares', use_log=False, scale_type='minmax'))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    print(f\"\\nTraining: {name}\")\n",
    "    model.fit()\n",
    "    \n",
    "    print(f\"Number of weights: {model.weight.shape[0]}\")\n",
    "    print(f\"Weights: {model.weight.flatten()}\")\n",
    "    \n",
    "    # Dự đoán trên tập validation và test\n",
    "    y_val_pred = model.predict(model.X_val)\n",
    "    y_test_pred = model.predict(model.X_test)\n",
    "    \n",
    "    # Tính MSE và MAE trên tập validation\n",
    "    val_mse = mse(model.y_val_original.reshape(-1, 1), y_val_pred)\n",
    "    val_mae = mae(model.y_val_original.reshape(-1, 1), y_val_pred)\n",
    "    \n",
    "    # Tính MSE và MAE trên tập test\n",
    "    test_mse = mse(model.y_test_original.reshape(-1, 1), y_test_pred)\n",
    "    test_mae = mae(model.y_test_original.reshape(-1, 1), y_test_pred)\n",
    "    \n",
    "    # In kết quả trên tập validation\n",
    "    print(f\"\\nPredictions vs True Values (Validation Set):\")\n",
    "    print(\"Index | Predicted Price | True Price\")\n",
    "    for i in range(min(len(model.y_val), 10)):  # In 10 dòng đầu\n",
    "        print(f\"{i:5d} | {y_val_pred[i, 0]:15.2f} | {model.y_val_original[i]:15.2f}\")\n",
    "    \n",
    "    print(f\"\\nValidation MSE: {val_mse:.4f}\")\n",
    "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "    \n",
    "    # In kết quả trên tập test\n",
    "    print(f\"\\nPredictions vs True Values (Test Set):\")\n",
    "    print(\"Index | Predicted Price | True Price\")\n",
    "    for i in range(min(len(model.y_test), 10)):  # In 10 dòng đầu\n",
    "        print(f\"{i:5d} | {y_test_pred[i, 0]:15.2f} | {model.y_test_original[i]:15.2f}\")\n",
    "    \n",
    "    print(f\"\\nTest MSE: {test_mse:.4f}\")\n",
    "    print(f\"Test MAE: {test_mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
